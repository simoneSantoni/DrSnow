2019-12-06 06:30:44,459 : INFO : collecting all words and their counts
2019-12-06 06:30:44,460 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types
2019-12-06 06:30:44,639 : INFO : pruned out 0 tokens with count <=1 (before 50051, after 50051)
2019-12-06 06:30:44,657 : INFO : pruned out 40661 tokens with count <=2 (before 50096, after 9435)
2019-12-06 06:30:44,720 : INFO : collected 34162 word types from a corpus of 130410 words (unigram + bigrams) and 1156 sentences
2019-12-06 06:30:44,720 : INFO : using 34162 counts as vocab in Phrases<0 vocab, min_count=50, threshold=5, max_vocab_size=50000>
2019-12-06 06:30:44,720 : INFO : collecting all words and their counts
2019-12-06 06:30:44,721 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types
2019-12-06 06:30:45,072 : INFO : pruned out 0 tokens with count <=1 (before 50015, after 50015)
2019-12-06 06:30:45,091 : INFO : pruned out 40728 tokens with count <=2 (before 50094, after 9366)
2019-12-06 06:30:45,294 : INFO : collected 34345 word types from a corpus of 129679 words (unigram + bigrams) and 1156 sentences
2019-12-06 06:30:45,294 : INFO : using 34345 counts as vocab in Phrases<0 vocab, min_count=50, threshold=5, max_vocab_size=50000>
2019-12-06 06:31:03,654 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2019-12-06 06:31:03,846 : INFO : built Dictionary(7557 unique tokens: ['-PRON-', 'a', 'about', 'activity', 'after']...) from 1156 documents (total 129489 corpus positions)
2019-12-06 06:31:04,890 : INFO : serializing temporary corpus to /tmp/9ed11d_corpus.txt
2019-12-06 06:31:04,986 : INFO : converting temporary corpus to MALLET format with mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex "\S+" --input /tmp/9ed11d_corpus.txt --output /tmp/9ed11d_corpus.mallet
